{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_api_key import import_json as read_db_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_info = read_db_secret(\"db_config/database_config.json\")\n",
    "\n",
    "host = db_info[\"host\"]\n",
    "user = db_info[\"user\"]\n",
    "password = db_info[\"password\"]\n",
    "db_port = db_info[\"port\"]\n",
    "db_name = db_info[\"db_name\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established\n"
     ]
    }
   ],
   "source": [
    "conn_string = f\"host={host} user={user} dbname={db_name} password={password}\"\n",
    "conn = psycopg2.connect(conn_string)\n",
    "print(\"Connection established\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://www.psycopg.org/docs/usage.html for usage of psycopg2\n",
    "# Open a cursor to the database - remember to close this after you have done everything!\n",
    "\n",
    "cur = conn.cursor()\n",
    "# If something goes wrong (you get transactionerror)- use the command below\n",
    "cur.execute(\"rollback\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_type(num):\n",
    "    try:\n",
    "        num = float(num)\n",
    "        result = isinstance(num, (int, float)) and num.is_integer()\n",
    "    except ValueError:\n",
    "        result = False\n",
    "\n",
    "    if result:\n",
    "        num_type = \"int\" if num.is_integer() else \"float\"\n",
    "        return num_type\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "#returns if a string is a date or not\n",
    "def is_date(s, date_formats=['%d-%m-%Y', '%m-%d-%Y', '%Y-%d-%m', '%Y-%m-%d']):\n",
    "    for date_format in date_formats:\n",
    "        try:\n",
    "            datetime.strptime(s, date_format)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extension(file_path):\n",
    "    # Find the last occurrence of '.' in the file path\n",
    "    dot_index = file_path.rfind('.')\n",
    "\n",
    "    # If '.' is found, slice the string to remove the extension\n",
    "    if dot_index != -1:\n",
    "        file_name_without_extension = file_path[:dot_index]\n",
    "    else:\n",
    "        # If '.' is not found, keep the original string\n",
    "        file_name_without_extension = file_path\n",
    "\n",
    "    return file_name_without_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for converting datetime to date\n",
    "def convert_datetime_columns_to_date(df):\n",
    "    for column in df.columns:\n",
    "        if pd.api.types.is_datetime64_any_dtype(df[column]):\n",
    "            df[column] = df[column].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_column_size(column, df, debug_print=False):\n",
    "    max_value = df[column].max()\n",
    "    if(debug_print):print(f\"Maxvalue was {max_value} for {column}\")\n",
    "\n",
    "    if pd.api.types.is_string_dtype(df[column]):  # Check if the column contains strings\n",
    "        max_length = df[column].str.len().max()\n",
    "        return f\"{column} VARCHAR({max_length})\"\n",
    "    elif pd.api.types.is_float_dtype(df[column]):  # Check if the column contains floats\n",
    "        if max_value < 1e-3:\n",
    "            return f\"{column} FLOAT\"\n",
    "        elif max_value < 1e38:\n",
    "            return f\"{column} REAL\"\n",
    "        else:\n",
    "            return f\"{column} DOUBLE\"\n",
    "    elif pd.api.types.is_integer_dtype(df[column]):  # Check if the column contains integers\n",
    "        if max_value < 256:\n",
    "            return f\"{column} TINYINT\"\n",
    "        elif max_value < 32768:\n",
    "            return f\"{column} SMALLINT\"\n",
    "        elif max_value < 2147483648:\n",
    "            return f\"{column} INT\"\n",
    "        else:\n",
    "            return f\"{column} BIGINT\"\n",
    "    elif pd.api.types.is_datetime64_any_dtype(df[column]):  # Check if the column contains datetime values\n",
    "        return f\"{column} DATE\"\n",
    "    #If for some reason the formatting is neither of these, set it as text as a failsafe\n",
    "\n",
    "    return f\"{column} TEXT\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Read files from the silver directory, and create tables with column name from the first row and populate each row later in the csv file\n",
    "def create_and_populate_tables(directory_path, db_name, user, password, host, port, table_prefix, debug_print=False):\n",
    "    # Connect to PostgreSQL database\n",
    "    conn = psycopg2.connect(dbname=db_name, user=user, password=password, host=host, port=port)\n",
    "    cursor = conn.cursor()\n",
    "    # Iterate through CSV files in the specified directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".json\"): #For every CSV file\n",
    "            json_path = os.path.join(directory_path, filename)\n",
    "            \n",
    "            #Remove the filename, will be used to create the column names\n",
    "            filename_no_ext = remove_extension(filename)\n",
    "            df = pd.read_json(json_path)\n",
    "\n",
    "            #Convert datetime to date, since pd always adds a timestamp for some reason\n",
    "            # convert_datetime_columns_to_date(df)\n",
    "\n",
    "            # Generate SQL query string\n",
    "            table_name = filename_no_ext # uses the table name that is the filename but with no file extension\n",
    "            table_name_full = table_prefix + table_name\n",
    "\n",
    "            #remove this later\n",
    "            cursor.execute(f\"DROP TABLE IF EXISTS {table_name_full};\")\n",
    "\n",
    "            sql_query = f\"CREATE TABLE IF NOT EXISTS {table_name_full} (\\n\"\n",
    "\n",
    "            # FUNCTION FOR ESTIMATING HOW LARGE EACH DATA TYPE NEEDS TO BE\n",
    "            # Loop through all values in all tables, and store the largest value for text as varchar, float and int types\n",
    "            # Add max values for text variable, float, int for each column. Where the float type corresponds with the largest value of that type for that column\n",
    "            # \n",
    "\n",
    "            \n",
    "            data_types = df.dtypes # set the type to be the types from the dataframe\n",
    "                    \n",
    "            for column in df.columns:\n",
    "                column_definition = estimate_column_size(column, df, debug_print)\n",
    "                if column_definition is not None:\n",
    "                    sql_query += \"    \" + column_definition + \",\\n\"\n",
    "\n",
    "            #We assume all the dates we get are in datetime\n",
    "            convert_datetime_columns_to_date(df)\n",
    "\n",
    "\n",
    "            # Remove the trailing comma and newline character\n",
    "            sql_query = sql_query.rstrip(\",\\n\")\n",
    "\n",
    "            # Close the CREATE TABLE statement\n",
    "            sql_query += \"\\n);\"\n",
    "            if(debug_print):print(\"SQL creation:\", sql_query)\n",
    "            cursor.execute(sql_query)\n",
    "            # Populating the database\n",
    "            columns = df.columns # set the columns to be the columns from the dataframe\n",
    "            for index, row in df.iterrows():\n",
    "                #row is a list, for value in row joins the values in the row with a comma\n",
    "                # row1[1,John,25]\n",
    "                #values 1, John, 25\n",
    "                values = \", \".join([f\"'{str(value)}'\" for value in row])\n",
    "\n",
    "                insert_query = f\"INSERT INTO {table_name_full} ({', '.join(columns)}) VALUES ({values});\"\n",
    "                if(debug_print):print(\"Inserting \",insert_query)\n",
    "                cursor.execute(insert_query)\n",
    "\n",
    "    # Commit and close the connection\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'silver/'\n",
    "table_prefix = 'emissions_'\n",
    "debug_print = False\n",
    "create_and_populate_tables(directory_path, db_name, user, password, host, db_port, table_prefix, debug_print)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
